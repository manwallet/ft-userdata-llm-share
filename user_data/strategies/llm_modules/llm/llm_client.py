"""
LLMå®¢æˆ·ç«¯æ¨¡å—
è´Ÿè´£ä¸LLM APIäº¤äº’ï¼Œæ”¯æŒå‡½æ•°è°ƒç”¨
"""
import logging
from typing import Dict, Any, List, Optional
import requests
import json
from datetime import datetime

logger = logging.getLogger(__name__)


class LLMClient:
    """LLM APIå®¢æˆ·ç«¯"""

    def __init__(self, llm_config: Dict[str, Any], function_executor):
        """
        åˆå§‹åŒ–LLMå®¢æˆ·ç«¯

        Args:
            llm_config: LLMé…ç½®
            function_executor: å‡½æ•°æ‰§è¡Œå™¨
        """
        self.api_base = llm_config.get("api_base", "http://host.docker.internal:3120")
        self.api_key = llm_config.get("api_key", "")
        self.model = llm_config.get("model", "qwen/qwen3-coder-30b")
        self.temperature = None  # ä½¿ç”¨ LM Studio çš„é…ç½®
        self.max_tokens = None  # ä½¿ç”¨ LM Studio çš„é…ç½®
        self.timeout = None  # ä¸è®¾ç½®è¶…æ—¶é™åˆ¶ï¼Œå…è®¸æ€è€ƒæ¨¡å‹æœ‰è¶³å¤Ÿæ—¶é—´æ¨ç†

        self.function_executor = function_executor

        # å¯¹è¯å†å²(ç”¨äºä¸Šä¸‹æ–‡ç®¡ç†)
        self.conversation_history: List[Dict[str, Any]] = []
        self.max_history_length = 10  # ä¿ç•™æœ€è¿‘Nè½®å¯¹è¯

        logger.info(f"LLMå®¢æˆ·ç«¯å·²åˆå§‹åŒ–: {self.model}")

    def call_with_functions(
        self,
        messages: List[Dict[str, str]],
        functions: Optional[List[Dict[str, Any]]] = None,
        max_iterations: int = 5
    ) -> Dict[str, Any]:
        """
        è°ƒç”¨LLMå¹¶æ”¯æŒå‡½æ•°è°ƒç”¨

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            functions: å¯ç”¨çš„å‡½æ•°åˆ—è¡¨
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°(é˜²æ­¢æ— é™å¾ªç¯)

        Returns:
            LLMå“åº”å’Œæ‰§è¡Œç»“æœ
        """
        if functions is None:
            functions = self.function_executor.get_all_tools_schema()

        iteration = 0
        current_messages = messages.copy()
        function_call_history = []

        while iteration < max_iterations:
            iteration += 1

            logger.debug(f"ğŸ”„ è¿­ä»£ {iteration}/{max_iterations} å¼€å§‹")

            try:
                # è°ƒç”¨LLM API
                response = self._call_api(current_messages, functions)

                if not response:
                    return {
                        "success": False,
                        "error": "APIè°ƒç”¨å¤±è´¥",
                        "iteration": iteration
                    }

                # è§£æå“åº”
                choice = response.get("choices", [{}])[0]
                message = choice.get("message", {})
                finish_reason = choice.get("finish_reason", "")

                # æå–æ¶ˆæ¯å†…å®¹ï¼ˆå…¼å®¹æ¨ç†æ¨¡å‹çš„ç‰¹æ®Šæ ¼å¼ï¼‰
                message_content = self._extract_message_content(message)

                # æ£€æŸ¥æ˜¯å¦æœ‰å‡½æ•°è°ƒç”¨
                tool_calls = message.get("tool_calls", [])

                if not tool_calls or finish_reason == "stop":
                    # æ²¡æœ‰å‡½æ•°è°ƒç”¨æˆ–å·²å®Œæˆï¼Œè¿”å›æœ€ç»ˆå“åº”
                    logger.debug(f"âœ… å†³ç­–å®Œæˆ (è¿­ä»£{iteration}, åŸå› : {finish_reason or 'æ— å‡½æ•°è°ƒç”¨'})")
                    return {
                        "success": True,
                        "message": message_content,
                        "function_calls": function_call_history,
                        "iterations": iteration,
                        "finish_reason": finish_reason
                    }

                # æ‰§è¡Œå‡½æ•°è°ƒç”¨
                logger.debug(f"ğŸ“ æœ¬æ¬¡è¿­ä»£éœ€è¦è°ƒç”¨ {len(tool_calls)} ä¸ªå‡½æ•°")
                function_results = []
                should_terminate = False  # æ˜¯å¦é‡åˆ°ç»ˆæ­¢æ€§å‡½æ•°

                for tool_call in tool_calls:
                    func_name = tool_call.get("function", {}).get("name", "")
                    func_args_str = tool_call.get("function", {}).get("arguments", "{}")

                    try:
                        func_args = json.loads(func_args_str) if isinstance(func_args_str, str) else func_args_str
                    except json.JSONDecodeError as e:
                        logger.error(f"è§£æå‡½æ•°å‚æ•°å¤±è´¥: {e}")
                        func_args = {}

                    # æ‰§è¡Œå‡½æ•°
                    result = self.function_executor.execute_function(func_name, func_args)

                    # æ£€æŸ¥æ˜¯å¦ä¸ºç»ˆæ­¢æ€§å‡½æ•°
                    if result.get("_is_terminal", False):
                        should_terminate = True
                        logger.info(f"ğŸ›‘ æ£€æµ‹åˆ°ç»ˆæ­¢æ€§å‡½æ•° '{func_name}'ï¼Œå†³ç­–æµç¨‹å°†ç»“æŸ")

                    # è®°å½•
                    function_call_history.append({
                        "function": func_name,
                        "arguments": func_args,
                        "result": result
                    })

                    function_results.append({
                        "role": "tool",
                        "tool_call_id": tool_call.get("id", ""),
                        "name": func_name,
                        "content": json.dumps(result, ensure_ascii=False)
                    })

                # å¦‚æœé‡åˆ°ç»ˆæ­¢æ€§å‡½æ•°ï¼Œç«‹å³è¿”å›
                if should_terminate:
                    logger.info(f"âœ… å†³ç­–å®Œæˆ (è¿­ä»£{iteration}, è°ƒç”¨ç»ˆæ­¢æ€§å‡½æ•°)")
                    return {
                        "success": True,
                        "message": message_content,
                        "function_calls": function_call_history,
                        "iterations": iteration,
                        "finish_reason": "terminal_function"
                    }

                # å°†å‡½æ•°è°ƒç”¨ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
                current_messages.append(message)
                current_messages.extend(function_results)

            except Exception as e:
                logger.error(f"LLMè°ƒç”¨å¤±è´¥ (è¿­ä»£{iteration}): {e}")
                return {
                    "success": False,
                    "error": str(e),
                    "iteration": iteration,
                    "function_calls": function_call_history
                }

        # è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆæå°‘å‘ç”Ÿï¼‰
        logger.debug(f"è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations}")
        return {
            "success": False,
            "error": "è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°",
            "iterations": max_iterations,
            "function_calls": function_call_history
        }

    def _call_api(
        self,
        messages: List[Dict[str, str]],
        functions: List[Dict[str, Any]]
    ) -> Optional[Dict[str, Any]]:
        """
        è°ƒç”¨LLM API

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            functions: å‡½æ•°åˆ—è¡¨

        Returns:
            APIå“åº”
        """
        try:
            url = f"{self.api_base}/v1/chat/completions"
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.api_key}"
            }

            payload = {
                "model": self.model,
                "messages": messages,
                "tools": [{"type": "function", "function": f} for f in functions],
                "tool_choice": "auto"
            }

            # åªæ·»åŠ é None çš„å¯é€‰å‚æ•°
            if self.temperature is not None:
                payload["temperature"] = self.temperature
            if self.max_tokens is not None:
                payload["max_tokens"] = self.max_tokens

            logger.debug(f"è°ƒç”¨LLM API: {self.model}")

            response = requests.post(
                url,
                json=payload,
                headers=headers,
                timeout=self.timeout
            )

            if response.status_code != 200:
                logger.error(f"APIè¿”å›é”™è¯¯: {response.status_code} - {response.text}")
                return None

            return response.json()

        except requests.Timeout:
            logger.error("APIè¯·æ±‚è¶…æ—¶")
            return None
        except Exception as e:
            logger.error(f"APIè°ƒç”¨å¼‚å¸¸: {e}")
            return None

    def _extract_message_content(self, message: Dict[str, Any]) -> str:
        """
        æå–æ¶ˆæ¯å†…å®¹ï¼Œå…¼å®¹æ¨ç†æ¨¡å‹çš„ç‰¹æ®Šå“åº”æ ¼å¼

        Args:
            message: APIè¿”å›çš„messageå¯¹è±¡

        Returns:
            æå–çš„æ¶ˆæ¯å†…å®¹
        """
        # æ£€æŸ¥å¹¶è®°å½•æ€è€ƒè¿‡ç¨‹ï¼ˆå¦‚æœæœ‰ï¼‰
        think = message.get("think", "")
        reasoning = message.get("reasoning", "")
        reasoning_content = message.get("reasoning_content", "")

        if think:
            logger.info(f"[æ¨¡å‹æ€è€ƒè¿‡ç¨‹]\n{think}")
        elif reasoning:
            logger.info(f"[æ¨¡å‹æ¨ç†è¿‡ç¨‹]\n{reasoning}")
        elif reasoning_content:
            logger.info(f"[æ¨¡å‹æ¨ç†å†…å®¹]\n{reasoning_content}")

        # ä¼˜å…ˆä½¿ç”¨ content å­—æ®µï¼ˆæ ‡å‡†æ ¼å¼ - æœ€ç»ˆå†³ç­–ï¼‰
        content = message.get("content", "")
        if content:
            return content

        # å¦‚æœæ²¡æœ‰ contentï¼Œå°è¯•ä½¿ç”¨ reasoning ç›¸å…³å­—æ®µ
        # æŸäº›æ¨ç†æ¨¡å‹å¯èƒ½åªè¿”å› reasoning è€Œä¸è¿”å› content
        if reasoning:
            logger.info("æœªæ‰¾åˆ° content å­—æ®µï¼Œä½¿ç”¨ reasoning ä½œä¸ºå“åº”")
            return reasoning

        if think:
            logger.info("æœªæ‰¾åˆ° content å­—æ®µï¼Œä½¿ç”¨ think ä½œä¸ºå“åº”")
            return think

        if reasoning_content:
            logger.info("æœªæ‰¾åˆ° content å­—æ®µï¼Œä½¿ç”¨ reasoning_content ä½œä¸ºå“åº”")
            return reasoning_content

        # å¦‚æœæœ‰tool_callsï¼Œè¯´æ˜LLMç›´æ¥è°ƒç”¨å‡½æ•°è€Œæ²¡æœ‰è¾“å‡ºæ–‡æœ¬ï¼Œè¿™æ˜¯æ­£å¸¸çš„
        if message.get("tool_calls"):
            logger.debug("æ¶ˆæ¯ä¸­åªæœ‰tool_callsï¼Œæ— æ–‡æœ¬å†…å®¹ï¼ˆæ­£å¸¸ï¼‰")
            return ""

        # å¦‚æœæ—¢æ²¡æœ‰å†…å®¹ä¹Ÿæ²¡æœ‰tool_callsï¼Œæ‰æ˜¯å¼‚å¸¸æƒ…å†µ
        logger.warning("æ¶ˆæ¯ä¸­æœªæ‰¾åˆ° contentã€thinkã€reasoningã€reasoning_content æˆ– tool_calls å­—æ®µ")
        return ""

    def simple_call(
        self,
        messages: List[Dict[str, str]]
    ) -> Optional[str]:
        """
        ç®€å•è°ƒç”¨(ä¸ä½¿ç”¨å‡½æ•°è°ƒç”¨)

        Args:
            æ¶ˆæ¯åˆ—è¡¨

        Returns:
            LLMå“åº”æ–‡æœ¬
        """
        try:
            url = f"{self.api_base}/v1/chat/completions"
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.api_key}"
            }

            payload = {
                "model": self.model,
                "messages": messages
            }

            # åªæ·»åŠ é None çš„å¯é€‰å‚æ•°
            if self.temperature is not None:
                payload["temperature"] = self.temperature
            if self.max_tokens is not None:
                payload["max_tokens"] = self.max_tokens

            response = requests.post(
                url,
                json=payload,
                headers=headers,
                timeout=self.timeout
            )

            if response.status_code != 200:
                logger.error(f"APIè¿”å›é”™è¯¯: {response.status_code}")
                return None

            data = response.json()
            content = data.get("choices", [{}])[0].get("message", {}).get("content", "")

            return content

        except Exception as e:
            logger.error(f"ç®€å•è°ƒç”¨å¤±è´¥: {e}")
            return None

    def manage_context_window(
        self,
        messages: List[Dict[str, str]],
        max_tokens: int = 6000
    ) -> List[Dict[str, str]]:
        """
        ç®¡ç†ä¸Šä¸‹æ–‡çª—å£ï¼Œé¿å…è¶…å‡ºtokené™åˆ¶

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            max_tokens: æœ€å¤§tokenæ•°

        Returns:
            ç²¾ç®€åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        # ç®€å•ä¼°ç®—: 1 token â‰ˆ 2.5 å­—ç¬¦
        estimated_tokens = sum(len(m.get("content", "")) for m in messages) / 2.5

        if estimated_tokens <= max_tokens:
            return messages

        # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œæœ€è¿‘çš„ç”¨æˆ·æ¶ˆæ¯
        system_messages = [m for m in messages if m.get("role") == "system"]
        other_messages = [m for m in messages if m.get("role") != "system"]

        # ä»åå¾€å‰ä¿ç•™æ¶ˆæ¯ï¼Œç›´åˆ°æ¥è¿‘tokené™åˆ¶
        kept_messages = []
        current_tokens = sum(len(m.get("content", "")) for m in system_messages) / 2.5

        for msg in reversed(other_messages):
            msg_tokens = len(msg.get("content", "")) / 2.5
            if current_tokens + msg_tokens > max_tokens * 0.9:  # ä¿ç•™10%ä½™é‡
                break
            kept_messages.insert(0, msg)
            current_tokens += msg_tokens

        return system_messages + kept_messages

    def add_to_history(self, role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°å†å²"""
        self.conversation_history.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        })

        # é™åˆ¶å†å²é•¿åº¦
        if len(self.conversation_history) > self.max_history_length * 2:
            self.conversation_history = self.conversation_history[-self.max_history_length * 2:]

    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history.clear()
        logger.info("å¯¹è¯å†å²å·²æ¸…ç©º")

    def get_history(self, include_timestamp: bool = False) -> List[Dict[str, Any]]:
        """è·å–å¯¹è¯å†å²"""
        if include_timestamp:
            return self.conversation_history.copy()

        return [
            {"role": m["role"], "content": m["content"]}
            for m in self.conversation_history
        ]

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "model": self.model,
            "api_base": self.api_base,
            "conversation_length": len(self.conversation_history),
            "max_history_length": self.max_history_length
        }
